{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93aab838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 6-4 단 3개의 짧은 문장으로 이루어진 텍스트 데이터를 처리하는 간단한 예제\n",
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f2dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "#  텍스트 데이터로부터 사전을 만들기 위해 모든 문장을 단어 단위로 쪼갠 후에 파이썬 딕셔너리(dict) 자료구조로 표현\n",
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a63a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "# 텍스트를 숫자로 바꾸려면 위의 딕셔너리가 {텍스트:인덱스} 구조\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf9cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리는 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용\n",
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a864a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 우리가 가진 텍스트 데이터를 숫자로 바꿔 표현\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8810ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7856dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b3bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48b1b65",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64/175354410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 6-5  Embedding 레이어를 활용하여 이전 스텝의 텍스트 데이터를 워드 벡터 텐서 형태로 다시 표현\n",
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76786f85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63/652254279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tensorflow에서는 tf.keras.preprocessing.sequence.pad_sequences라는 편리한 함수를 통해 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                        \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<PAD>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                        \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                        maxlen=5)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Tensorflow에서는 tf.keras.preprocessing.sequence.pad_sequences라는 편리한 함수를 통해 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8abdf0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.04152847  0.03572309  0.02373897  0.00916681]\n",
      "  [-0.00337473  0.03022562 -0.02032001 -0.04211795]\n",
      "  [ 0.03365971 -0.03534748 -0.01154324 -0.02802454]\n",
      "  [ 0.03219444  0.03069307  0.02186166 -0.00829   ]\n",
      "  [-0.02498673  0.04481871 -0.02008503  0.00525038]]\n",
      "\n",
      " [[ 0.04152847  0.03572309  0.02373897  0.00916681]\n",
      "  [-0.00337473  0.03022562 -0.02032001 -0.04211795]\n",
      "  [-0.0380839  -0.03408235  0.03448571  0.00665121]\n",
      "  [-0.01360493  0.03017182  0.03188504  0.008445  ]\n",
      "  [-0.02498673  0.04481871 -0.02008503  0.00525038]]\n",
      "\n",
      " [[ 0.04152847  0.03572309  0.02373897  0.00916681]\n",
      "  [-0.00697669  0.04038587 -0.03811657  0.01653655]\n",
      "  [-0.00337473  0.03022562 -0.02032001 -0.04211795]\n",
      "  [ 0.03365971 -0.03534748 -0.01154324 -0.02802454]\n",
      "  [-0.01406109  0.03102595 -0.03026627 -0.02365117]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 위에 시도했던 output = embedding(raw_inputs)을 다시 시도\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafd8369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6-6 RNN 모델을 사용하여 이전 스텝의 텍스트 데이터를 처리하는 예제 코드를 구현\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용. 이때 LSTM state 벡터의 차원수는 8로 하였다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f07f7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6-7  RNN이 아니라 1-D Convolution Neural Network(1-D CNN)를 사용\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))  # 시간적 데이터에 대한 평균 풀링\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())  # 시간적 데이터에 대한 글로벌 최대값 풀링 작업.\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a7e4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#GlobalMaxPooling1D() 레이어 하나만 사용하는 방법도 생각\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3be1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "# 6-8\n",
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f773e2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "823fbca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드했음을 확인할 수 있다.\n",
    "# 이미 텍스트가 encode되었으므로 IMDb 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e881f917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# IMDb 데이터셋의 텍스트 인코딩을 위한 word_to_index, index_to_word는 아래와 같이 보정되어야 함. \n",
    "# 아래 내용은 Tensorflow 튜토리얼의 가이드를 반영하여 작성\n",
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있다. word_to_index는 IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79df5b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a89a9fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안돼!!\n",
    "# 문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 된다. 이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋다.\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e8f4c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'post'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'post'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8f45f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6-9 RNN 모델을 직접 설계해 보겠습니다. 이전 스텝의 실습 내용을 참고\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    " \n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용. 이때 LSTM state 벡터의 차원수는 8로 하였다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccb41922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# model 훈련 전에, 훈련용 데이터셋 25000건 중 10000건을 분리하여 검증셋(validation set)으로 사용\n",
    "\n",
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54e70627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 47ms/step - loss: 0.6917 - accuracy: 0.5620 - val_loss: 0.6877 - val_accuracy: 0.6445\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6740 - accuracy: 0.7141 - val_loss: 0.6498 - val_accuracy: 0.7241\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.5611 - accuracy: 0.7909 - val_loss: 0.5069 - val_accuracy: 0.7789\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.4407 - accuracy: 0.8447 - val_loss: 0.4364 - val_accuracy: 0.8255\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.3606 - accuracy: 0.8793 - val_loss: 0.3850 - val_accuracy: 0.8517\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.3050 - accuracy: 0.8974 - val_loss: 0.3810 - val_accuracy: 0.8503\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2785 - accuracy: 0.9045 - val_loss: 0.3925 - val_accuracy: 0.8316\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2603 - accuracy: 0.9078 - val_loss: 0.3926 - val_accuracy: 0.8399\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2295 - accuracy: 0.9215 - val_loss: 0.3524 - val_accuracy: 0.8540\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1875 - accuracy: 0.9426 - val_loss: 0.3567 - val_accuracy: 0.8596\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1603 - accuracy: 0.9537 - val_loss: 0.3587 - val_accuracy: 0.8627\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1383 - accuracy: 0.9613 - val_loss: 0.3619 - val_accuracy: 0.8630\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1199 - accuracy: 0.9686 - val_loss: 0.3759 - val_accuracy: 0.8624\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1044 - accuracy: 0.9738 - val_loss: 0.3973 - val_accuracy: 0.8549\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0952 - accuracy: 0.9769 - val_loss: 0.4091 - val_accuracy: 0.8570\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0852 - accuracy: 0.9801 - val_loss: 0.4212 - val_accuracy: 0.8585\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0742 - accuracy: 0.9839 - val_loss: 0.4487 - val_accuracy: 0.8586\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0692 - accuracy: 0.9853 - val_loss: 0.4679 - val_accuracy: 0.8563\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0619 - accuracy: 0.9879 - val_loss: 0.4754 - val_accuracy: 0.8525\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0587 - accuracy: 0.9881 - val_loss: 0.4877 - val_accuracy: 0.8521\n"
     ]
    }
   ],
   "source": [
    "# model 학습을 시작\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b94e81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.5265 - accuracy: 0.8404\n",
      "[0.5265427827835083, 0.840399980545044]\n"
     ]
    }
   ],
   "source": [
    "# 학습이 끝난 모델을 테스트셋으로 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5068f125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31a56ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvsUlEQVR4nO3deZgU5bn38e/NJiDgBm4gDBqQqMAAAygoijER0AOuEQQVjSIm7olKJFEOhlyJehJeI2rQxCUHReMxBCMEVwQlRhYHFERFAjq4IcqigLLc7x9PDdMM07N2dfdM/z7X1Vd3V1dV313TU3c/a5m7IyIiuatepgMQEZHMUiIQEclxSgQiIjlOiUBEJMcpEYiI5DglAhGRHKdEICllZjPN7KJUr5tJZrbKzE6JYb9uZt+JHt9nZr+szLrVeJ/hZvZsdeMsZ78nmVlRqvcr6dcg0wFI5pnZVwlPmwLfADui55e7+5TK7svdB8axbl3n7qNTsR8zywP+AzR09+3RvqcAlf4bSu5RIhDcvVnxYzNbBVzq7s+XXs/MGhSfXESk7lDVkCRVXPQ3s5vM7BPgQTPbz8z+YWZrzezL6HGbhG1mm9ml0eORZvaKmd0ZrfsfMxtYzXXbm9kcM9tkZs+b2SQz+98kcVcmxtvM7NVof8+aWcuE1y8ws9Vmts7MxpZzfHqb2SdmVj9h2ZlmtiR63MvM/mVm683sYzO728waJdnXQ2b2q4TnN0TbfGRml5Ra9zQze8PMNprZh2Y2LuHlOdH9ejP7ysyOKz62Cdv3MbP5ZrYhuu9T2WNTHjP7brT9ejNbamaDE14bZGbLon2uMbOfRctbRn+f9Wb2hZnNNTOdl9JMB1wqcjCwP9AOGEX4zjwYPW8LbAHuLmf73sA7QEvgduBPZmbVWPdR4HXgAGAccEE571mZGM8HLgYOBBoBxSemo4B7o/0fGr1fG8rg7v8GvgZOLrXfR6PHO4Dros9zHPA94MflxE0Uw4Aonu8DHYDS7RNfAxcC+wKnAVeY2RnRa/2i+33dvZm7/6vUvvcHngHuij7b74BnzOyAUp9hj2NTQcwNgaeBZ6PtrgKmmNmR0Sp/IlQzNgeOAV6Mlv8UKAJaAQcBNwOa9ybNlAikIjuBW939G3ff4u7r3P3/3H2zu28CJgAnlrP9ane/3913AA8DhxD+4Su9rpm1BXoCt7j7t+7+CjA92RtWMsYH3f1dd98CPAHkR8vPAf7h7nPc/Rvgl9ExSOYxYBiAmTUHBkXLcPeF7v6au29391XAH8uIoyw/jOJ7y92/JiS+xM83293fdPed7r4ker/K7BdC4njP3f8SxfUYsBz4r4R1kh2b8hwLNAN+E/2NXgT+QXRsgG3AUWbWwt2/dPdFCcsPAdq5+zZ3n+uaAC3tlAikImvdfWvxEzNramZ/jKpONhKqIvZNrB4p5ZPiB+6+OXrYrIrrHgp8kbAM4MNkAVcyxk8SHm9OiOnQxH1HJ+J1yd6L8Ov/LDPbCzgLWOTuq6M4OkbVHp9EcfyaUDqoyG4xAKtLfb7eZvZSVPW1ARhdyf0W73t1qWWrgdYJz5MdmwpjdvfEpJm437MJSXK1mb1sZsdFy+8AVgDPmtlKMxtTuY8hqaREIBUp/evsp8CRQG93b0FJVUSy6p5U+BjY38yaJiw7rJz1axLjx4n7jt7zgGQru/sywglvILtXC0GoYloOdIjiuLk6MRCqtxI9SigRHebu+wD3Jey3ol/THxGqzBK1BdZUIq6K9ntYqfr9Xft19/nuPoRQbTSNUNLA3Te5+0/d/XBgMHC9mX2vhrFIFSkRSFU1J9S5r4/qm2+N+w2jX9gLgHFm1ij6Nflf5WxSkxifBE43s+Ojht3xVPx/8ihwDSHh/LVUHBuBr8ysE3BFJWN4AhhpZkdFiah0/M0JJaStZtaLkICKrSVUZR2eZN8zgI5mdr6ZNTCz84CjCNU4NfFvQunhRjNraGYnEf5GU6O/2XAz28fdtxGOyU4AMzvdzL4TtQVtILSrlFcVJzFQIpCqmgg0AT4HXgP+mab3HU5ocF0H/Ap4nDDeoSwTqWaM7r4U+Anh5P4x8CWhMbM8xXX0L7r75wnLf0Y4SW8C7o9irkwMM6PP8CKh2uTFUqv8GBhvZpuAW4h+XUfbbia0ibwa9cQ5ttS+1wGnE0pN64AbgdNLxV1l7v4t4cQ/kHDc7wEudPfl0SoXAKuiKrLRhL8nhMbw54GvgH8B97j7SzWJRarO1C4jtZGZPQ4sd/fYSyQidZ1KBFIrmFlPMzvCzOpF3SuHEOqaRaSGNLJYaouDgacIDbdFwBXu/kZmQxKpG1Q1JCKS41Q1JCKS42pd1VDLli09Ly8v02GIiNQqCxcu/NzdW5X1Wq1LBHl5eSxYsCDTYYiI1CpmVnpE+S6qGhIRyXFKBCIiOS7WRGBmA8zsHTNbUdZkUmb2ezMrjG7vmtn6OOMREZE9xdZGEM30OIkwp3oRMN/MpkeTdAHg7tclrH8V0C2ueESk+rZt20ZRURFbt26teGXJqMaNG9OmTRsaNmxY6W3ibCzuBaxw95UAZjaVMBp0WZL1h5GGCcxEpOqKiopo3rw5eXl5JL+ukGSau7Nu3TqKiopo3759pbeLs2qoNbvPqV7E7nOe72Jm7YD27Dm5VkpMmQJ5eVCvXrifost4i1TJ1q1bOeCAA5QEspyZccABB1S55JYt3UeHAk9GV6bag5mNIlwmkbZtS0/NXr4pU2DUKNgcXdJk9erwHGD48OTbicjulARqh+r8neIsEaxh94trtCH5xS+GEl3eryzuPtndC9y9oFWrMsdDJDV2bEkSKLZ5c1guIiLxJoL5QAczax9d4GMoZVxnNrpgx36EuchT7oMPqrZcRLLPunXryM/PJz8/n4MPPpjWrVvvev7tt9+Wu+2CBQu4+uqrK3yPPn36pCTW2bNnc/rpp6dkX+kSWyJw9+3AlcAs4G3gCXdfambjzWxwwqpDgalxXbA6WU1SFWuYRKQKUt0ud8ABB1BYWEhhYSGjR4/muuuu2/W8UaNGbN++Pem2BQUF3HXXXRW+x7x582oWZC0W6zgCd5/h7h3d/Qh3nxAtu8XdpyesM87dY7tg9YQJ0LTp7svM4Kqr4npHkdxW3C63ejW4l7TLpbqTxsiRIxk9ejS9e/fmxhtv5PXXX+e4446jW7du9OnTh3feeQfY/Rf6uHHjuOSSSzjppJM4/PDDd0sQzZo127X+SSedxDnnnEOnTp0YPnw4xb9TZ8yYQadOnejRowdXX311hb/8v/jiC8444wy6dOnCsccey5IlSwB4+eWXd5VounXrxqZNm/j444/p168f+fn5HHPMMcydOze1B6wcdX5k8fDhMHkytGsXEkCrViExjBsHjz5a4eaAeh2JVEU62+WKioqYN28ev/vd7+jUqRNz587ljTfeYPz48dx8881lbrN8+XJmzZrF66+/zn//93+zbdu2PdZ54403mDhxIsuWLWPlypW8+uqrbN26lcsvv5yZM2eycOFC1q5dW2F8t956K926dWPJkiX8+te/5sILLwTgzjvvZNKkSRQWFjJ37lyaNGnCo48+yqmnnkphYSGLFy8mPz+/RsemKup8IoCQDFatgp074bPPYNky6No1LL/00j2/tInS9etGpK5IZ7vcueeeS/369QHYsGED5557LscccwzXXXcdS5cuLXOb0047jb322ouWLVty4IEH8umnn+6xTq9evWjTpg316tUjPz+fVatWsXz5cg4//PBd/fOHDRtWYXyvvPIKF1xwAQAnn3wy69atY+PGjfTt25frr7+eu+66i/Xr19OgQQN69uzJgw8+yLhx43jzzTdp3rx5dQ9LleVEIiitbVuYPRtuvhn+/Gfo2ROSfGfU60ikitLZLrf33nvvevzLX/6S/v3789Zbb/H0008n7Uu/11577Xpcv379MtsXKrNOTYwZM4YHHniALVu20LdvX5YvX06/fv2YM2cOrVu3ZuTIkTzyyCMpfc/y5GQiAGjQILQfzJoFn38eksEDD4Rf/YnU60ikaspql2vaNCyP04YNG2jdOoxZfeihh1K+/yOPPJKVK1eyatUqAB5//PEKtznhhBOYElUfzJ49m5YtW9KiRQvef/99OnfuzE033UTPnj1Zvnw5q1ev5qCDDuKyyy7j0ksvZdGiRSn/DMnkbCIo9v3vw+LF0LcvXHYZnH8+bNxY8rp6HYlUTel2uXbtwvO4B3DeeOON/PznP6dbt24p/wUP0KRJE+655x4GDBhAjx49aN68Ofvss0+524wbN46FCxfSpUsXxowZw8MPPwzAxIkTOeaYY+jSpQsNGzZk4MCBzJ49m65du9KtWzcef/xxrrnmmpR/hmRq3TWLCwoKPI4L0+zcCb/5DdxyS2gQfvxx6NFjz5HJEH7dpOOLLZIt3n77bb773e9mOoyM++qrr2jWrBnuzk9+8hM6dOjAddddV/GGaVbW38vMFrp7QVnr53yJoFi9eqHNYPZs+OYbOO44uOuuUELIxK8bEck+999/P/n5+Rx99NFs2LCByy+/PNMhpYRKBGVYtw4uvhiefhqGDAkNyvvvH+tbimQ1lQhqF5UIUuCAA+Dvf4ff/x5mzID8fHj11UxHJSISDyWCJMzg2mth3jxo2BBOPBHuuCPTUYmIpJ4SQQUKCuCNN0IV0Y03wptvZjoiEZHUUiKohBYt4L77oH59jSgWkbpHiaCSWrWCAQNCIti5M9PRiOSW/v37M2vWrN2WTZw4kSuuuCLpNieddBLFHUsGDRrE+vXr91hn3Lhx3HnnneW+97Rp01i2rOQKu7fccgvPP/98FaIvWzZNV61EUAUjRkBREcyZk+lIRHLLsGHDmDp16m7Lpk6dWqn5fiDMGrrvvvtW671LJ4Lx48dzyimnVGtf2UqJoAoGD4ZmzeB//zfTkYjklnPOOYdnnnlm10VoVq1axUcffcQJJ5zAFVdcQUFBAUcffTS33nprmdvn5eXx+eefAzBhwgQ6duzI8ccfv2uqaghjBHr27EnXrl05++yz2bx5M/PmzWP69OnccMMN5Ofn8/777zNy5EiefPJJAF544QW6detG586dueSSS/jmm292vd+tt95K9+7d6dy5M8uXLy/382V6uupsuWZxrdC0KZx1Fvz1r3D33dC4caYjEkm/a6+FwsLU7jM/HyZOTP76/vvvT69evZg5cyZDhgxh6tSp/PCHP8TMmDBhAvvvvz87duzge9/7HkuWLKFLly5l7mfhwoVMnTqVwsJCtm/fTvfu3enRowcAZ511FpdddhkAv/jFL/jTn/7EVVddxeDBgzn99NM555xzdtvX1q1bGTlyJC+88AIdO3bkwgsv5N577+Xaa68FoGXLlixatIh77rmHO++8kwceeCDp5yuernratGm8+OKLXHjhhRQWFu6arrpv37589dVXNG7cmMmTJ3PqqacyduxYduzYwebypk+uJJUIqmjEiDAX0T/+kelIRHJLYvVQYrXQE088Qffu3enWrRtLly7drRqntLlz53LmmWfStGlTWrRoweDBJRdLfOuttzjhhBPo3LkzU6ZMSTqNdbF33nmH9u3b07FjRwAuuugi5iTUG5911lkA9OjRY9dEdclkerpqlQiq6OST4eCDQ6NxqR8IIjmhvF/ucRoyZAjXXXcdixYtYvPmzfTo0YP//Oc/3HnnncyfP5/99tuPkSNHJp1+uiIjR45k2rRpdO3alYceeojZs2fXKN7iqaxrMo31mDFjOO2005gxYwZ9+/Zl1qxZu6arfuaZZxg5ciTXX3/9rgveVJdKBFVUv36Yf+iZZ+CLLzIdjUjuaNasGf379+eSSy7ZVRrYuHEje++9N/vssw+ffvopM2fOLHcf/fr1Y9q0aWzZsoVNmzbx9NNP73pt06ZNHHLIIWzbtm3X1NEAzZs3Z9OmTXvs68gjj2TVqlWsWLECgL/85S+ceOKJ1fpsmZ6uWomgGkaMgG3bQluBiKTPsGHDWLx48a5EUDxtc6dOnTj//PPp27dvudt3796d8847j65duzJw4EB69uy567XbbruN3r1707dvXzp16rRr+dChQ7njjjvo1q0b77///q7ljRs35sEHH+Tcc8+lc+fO1KtXj9GjR1frc2V6umpNOlcN7nDMMWEiujReX1okYzTpXO2iSefSwCyUCl55Bf7zn0xHIyJSM0oE1XT++eH+0UczG4eISE3FmgjMbICZvWNmK8xsTJJ1fmhmy8xsqZnVmtNqu3ZwwglhcFktq10TqZbaVo2cq6rzd4otEZhZfWASMBA4ChhmZkeVWqcD8HOgr7sfDVwbVzxxGDECli+HNF5jWiQjGjduzLp165QMspy7s27dOhpXcbRrnOMIegEr3H0lgJlNBYYAiaM9LgMmufuXAO7+WYzxpNy558JVV4UxBdHgRJE6qU2bNhQVFbF27dpMhyIVaNy4MW3atKnSNnEmgtbAhwnPi4DepdbpCGBmrwL1gXHu/s/SOzKzUcAogLZt28YSbHXstx+cdho89hjcfjs00PA8qaMaNmxI+/btMx2GxCTTjcUNgA7AScAw4H4z27f0Su4+2d0L3L2gVatW6Y2wAiNGwCefwIsvZjoSEZHqiTMRrAEOS3jeJlqWqAiY7u7b3P0/wLuExFBrDBoE++6rGUlFpPaKMxHMBzqYWXszawQMBaaXWmcaoTSAmbUkVBWtjDGmlGvcOLQVPPUUfP11pqMREam62BKBu28HrgRmAW8DT7j7UjMbb2bFU/7NAtaZ2TLgJeAGd18XV0xxGTEiJIG//z3TkYiIVJ2mmEiBnTshLy9MOzFjRqajERHZk6aYiFm9ejB8ODz7LHxWqzrAiogoEaTMiBGwYwc8/nimIxERqRolghQ5+uhwuT31HhKR2kaJIIVGjIDXX4d33919+ZQpoQ2hXr1wn3DNCxGRjFMiSKFhw8IU1Ykn+ilTYNQoWL06TE63enV4rmQgItlCiSCFDj0Uvve93WckHTsWNm/efb3Nm8NyEZFsoESQYiNGwMqV8Npr4fkHH5S9XrLlIiLppkSQYmeeCU2alDQaJ5sjL4vmzhORHKdEkGItWsDgwaEb6bZtMGECNG26+zpNm4blIiLZQIkgBiNGwLp1MGtWGGg2eXK4oplZuJ88OSwXEckGmmIiBtu2wSGHwCmnwNSpmY5GRERTTKRdw4YwdGiYhG7jxkxHIyJSPiWCmIwYAVu3humpRUSymRJBTHr3hiOO0JQTIpL9lAhiYhZKBS++CGtKX5dNRCSLKBHEaPjwMML4sccyHYmISHJKBDHq0CFUEWleIRHJZkoEMRs+HAoL4a23Mh2JiEjZlAhidt55UL++SgUikr2UCGJ24IFw6qkhEezcmeloRET2pESQBiNGwIcfwty5mY5ERGRPSgRpMGQINGumMQUikp1iTQRmNsDM3jGzFWY2pozXR5rZWjMrjG6XxhlPpjRtCmedBX/9K6xfn+loRER2F1siMLP6wCRgIHAUMMzMjipj1cfdPT+6PRBXPJl29dXw1VcwenTJ1ctERLJBnCWCXsAKd1/p7t8CU4EhMb5fVuvRA267LVyn4MEHMx2NiEiJOBNBa+DDhOdF0bLSzjazJWb2pJkdVtaOzGyUmS0wswVr166NI9a0uOmmcE3jq66Ct9/OdDQiIkGmG4ufBvLcvQvwHPBwWSu5+2R3L3D3glatWqU1wFSqVw8eeSS0GQwbFmYnFRHJtDgTwRog8Rd+m2jZLu6+zt2/iZ4+APSIMZ6scOih8PDDsHgx3HhjpqMREYk3EcwHOphZezNrBAwFpieuYGaHJDwdDOREhcmgQXDttfCHP8DTT2c6GhHJVp9+Ck8+GTqb5OfD3/4Wz/s0iGe34O7bzexKYBZQH/izuy81s/HAAnefDlxtZoOB7cAXwMi44sk2v/kNvPwyXHxxKB20Lqv1RERyhjusXh0Gns6ZE27vvhtea9oU+vSBJk3ieW9dsziD3n0XuneHnj3h+efDnEQikhvcYfny3U/8H0bda/bdF044Afr1C/fdu4dL4NZEedcsjq1EIBXr2BHuvjuUCn7zGxg7NtMRiUhcduwIpf85c8LJf+5cKO4EefDB4aR/443h/phjQueSdFEiyLCLLoLnnoNbb4X+/UPxT0RqJ3dYtw7eey+U+N97b/fHX38d1svLg4EDw0m/Xz/4znfCVQ0zRYkgw8zg3nvhtddCl9LFi0OxUESy14YNe57kix8nTiNTv3446XfsGE74vXuHqp7DyhwxlTlKBFmgRYtwOcu+feGyy+CJJzL760BESuzcCS+9FP4vly4NJ/zPPit53Syc2Dt0CD/mOnQIt44dQxJo1ChjoVeaEkGW6NULJkwIo48feCAkBBHJnBUrwpifRx6BDz4IP9jy8+G//iuc5ItP+EccEV9vnnRRIsgiP/tZ6D10zTWhdHBUWVP0iUhsNm4Mv/wfeghefTU02P7gB/Db34bp5Gv7CT8ZJYIsUjwFRdeuMHQo/PvfdfeLJ5ItduwIVT8PPQRPPQVbtkCnTqEn34gRuTHGR4kgyxx8cCiODhwIN9wQupeKSOq9+25J1U9RUeikMXJk6MnXq1dutdMpEWShAQPgpz+F//kfOOUUOOOMTEckUjds2FBS9TNvXiiFn3pq+F8bPBgaN850hJmR6dlHJYlf/zpcw+CSS0pGG4pI9bz9dqjmOfhgGDUKvvwSbr89/G/NmAE//GHuJgFQIshajRqFLqXbtoXGqnbtwq+XvDyYMiXT0YnUDkVFcOmlYaTu9Onhh9Xrr4duoDfcEGYDFlUNZbUOHcKvmPvuK1m2enX4RQMwfHhm4hLJdl9+GRp777orjAO4+mq4+WaoxZcziZVKBFlu5sw9l23erHmJRMqyZUuo8jn8cLjjDjj3XHjnHfj975UEyqNEkOU++KBqy0Vy0fbtYSBmhw5hUGafPlBYGHoE5eVlOrrsp0SQ5dq2rdpykVziDtOmQefOYTT+YYeF63w88wx06ZLp6GoPJYIsN2FCuChFIrPQvVQkl82ZE0bgn3lmeP7UU6FLaL9+mY2rNlIiyHLDh8PkyaHXkFno/rbXXuEyl2vWVLy9SF3z5ptw+ulw4omhivT++8OyM8/MrUFgqaREUAsMHw6rVoXeDx9/DC+8EO7794ePPsp0dCLpsXp1GPXbtWuYB+i3vw0zgV56KTRQ/8ca0eGrhfr0gVmzwojI/v3DPCnqDy11zSefwCuvhNvcuaHxt1Gj0P9/zBjYb79MR1h3KBHUUkoGUpe4h7l/Ek/8778fXmvSBI49Fn7xi9Ag3KZNZmOti5QIarE+feCf/wxzE/XvD7NnwyGHZDoqkYpt2wZvvFFy4n/llZLr97ZsCccfD1dcEe5TceF2KZ8SQS3Xt28YdDZwYEnJQMlAss2mTWFa9blzw0n/tdfCwEgIg78GDQon/eOPhyOPVKNvusWaCMxsAPD/gPrAA+7+myTrnQ08CfR09wVxxlQXHX98SAbFJQMlA8kk99Cb59VXw23ePFiyJHR2qFcvNPb+6Efh2r19+6pKMxvElgjMrD4wCfg+UATMN7Pp7r6s1HrNgWuAf8cVSy44/viSaqKTTw7J4OCDMx2V5IJt20JD7rx5JSf/4t5szZqV1O/36QPHHRcu+SjZJc4SQS9ghbuvBDCzqcAQYFmp9W4DfgvcEGMsOSExGRSXDJQMJNW+/BL+9a+SX/uvv15SzdOuXejf37dvOPF37qyunbVBpf5EZrY3sMXdd5pZR6ATMNPdt5WzWWsgcSb9IqB3qf12Bw5z92fMLGkiMLNRwCiAtppboVzF1UQDB4aSwYsvKhlIzbiH+v2HHw6jeZdFP+Xq14du3UJPnj59wk09emqnyubqOcAJZrYf8CwwHzgPqPZEyGZWD/gdMLKidd19MjAZoKCgwKv7nrnihBPCxTYGDSqpJjrooExHBevXh+vDevQXrOr93nvDPvukJVQh/Mp/7DGYNCn08GnWLEzfcP754Rd/z57hbyK1X2UTgbn7ZjP7EXCPu99uZoUVbLMGOCzheZtoWbHmwDHAbAtdBA4GppvZYDUY11y/fiXJoLiaKJ3J4JtvYNGiUIVQfKvplBj16oW5l266Sb1K4vTee3DvvfDggyF5H3NMeD5iREgGUvdUOhGY2XGEEsCPomX1K9hmPtDBzNoTEsBQ4PziF919A9Ay4Q1mAz9TEkid4mSQWE0UVzL46KNwsp83L9wvXAjffhtea9culFK6dy+5HGDxibwq988+Cz//eaiTfughNTqm0o4dYcbOe+4JAxUbNICzz4af/CRUNyrx1m2VTQTXAj8H/ubuS83scOCl8jZw9+1mdiUwi5A0/hxtOx5Y4O7TaxC3VFJiyaB379CDo2XL8m8VXbu1uJdI4om/+PoIe+0VrrV89dWhh8hxx6WuK+tll8HEiWGKgZ49w2yTRx+dmn3nqrVr4U9/ClfBW70aWreG8ePD/D3qgpw7zL1qVe5R3X4zd98YT0jlKygo8AULVGioqrlzQxe+Tz6Bzz+HL75Ivu7ee5edIOrVg/nzYcEC2Lo1rNumTUm3wOOOg/z8kAzi9PLL4WLjX38Nf/5zeCyVV9z4O2kSPPFEKLn17x9+/Q8erFG8dZWZLXT3gjJfq0wiMLNHgdHADkKVTwvg/7n7HakMtDKUCFJj+/bQDfDzzyt/27o19BJJPPFnqpfImjXhMoT/+hdcf32YiVLdFMu3eTNMnRoSwKJF0Lx5mM3zxz+G734309FJ3MpLBJX91znK3Tea2XBgJjAGWAikPRFIajRoEK7hWpXruLpnT11x69ZhbqXrr4ff/S60STz+eHb0jsomH34Y2laefTbU/W/YEKrT7rknNP42b57pCCUbVDYRNDSzhsAZwN3uvs3M1I0zx2RLEijWqBHcfXdo+7j88tAY/eSToaSSq77+OlSdFZ/4ly8Pyw89NFy45eKLQ8N9tv0tJbMqmwj+CKwCFgNzzKwdkJE2ApHSLrggXJ/2rLPCqNaJE8PMlblwstu5ExYvDif9Z58No32//TY0+J94Ymhg/8EPQikgF46HVE+VG4t3bWjWwN23pzieCqmNoOqmTIGxY0PPnrZtQ1/84dUeCpi9vvwyJIVnngn399235/We64KPPoLnngsn/ueeK5m+uUuXcNI/9dTQ5bOi3l+SW2rcRmBm+wC3AsWXhX4ZGA9sSEmEEpspU2DUqJK5YFavDs+h7iWD/faD6dPhV7+CcePCjJdPPRWmOa4Nvv021OGvX1/2bc2acJnSt94K6x94YMmJ/5RT1N1Tqq+yvYb+D3gLeDhadAHQ1d3PijG2MqlEUDV5eeHkX1q7duE6yHXVjBkliW7KlDCOIpW2bQvJtfi2Zcvuz8t67euvyz/RFyfrZPbaK0ztcOqpIQF06RK69IpURiq6jxa6e35Fy9JBiaBq6tUrmasnkVmoX67LVq4Mo2MXL4Zbb4Vf/nLPE6d7OAl/9lmoYinv/vPPS07u26tRKdqgAey7b/VvTZuqnl+qLxXdR7eY2fHu/kq0w77AllQFKPFp27bsEkEuTOJ6+OGh8fSKK0JV0UsvhW6nn31WcoJfuzb5SX3ffUP32gMPhO98J4zKbtYsnJBL35o0KXt54msaqCXZqrKJYDTwSNRWAPAlcFE8IUkqTZiwexsBhJPShAmZiymdmjYN8xIdeyzcdhsUFYWTe15emKbiwANLTvaJj1u2DN1TRXJBlXoNmVkLgGhw2bXuPjGuwJJR1VDV5UqvIRFJrsZtBEl2+oG7p72CQYlARKTqyksENelzoGYrEZE6oCaJQFNMiIjUAeU2FpvZJso+4RvQJJaIREQkrcpNBO6uuQlFROo4jUsUEclxSgQiIjlOiUBEJMcpEYiI5DglAhGRHKdEIBWaMiXMzVOvXrifMiXTEYlIKsWaCMxsgJm9Y2YrzGxMGa+PNrM3zazQzF4xs6PijEeqrvjCNqtXhymbiy9so2QgUndUe66hCndsVh94F/g+UATMB4a5+7KEdVq4+8bo8WDgx+4+oLz9aq6h9MrVC9uI1DVxzTVUkV7ACndf6e7fAlOBIYkrFCeByN5o2oqs88EHVVsuIrVPnImgNfBhwvOiaNluzOwnZvY+cDtwdYzxSDUku4BNLlzYRiRXZLyx2N0nufsRwE3AL8pax8xGmdkCM1uwdu3a9AaY4yZMCBd3SZRLF7YRyQVxJoI1wGEJz9tEy5KZCpxR1gvuPtndC9y9oFWrVqmLUCo0fDhMnhzaBMzC/eTJurCNSF1S2UtVVsd8oIOZtSckgKHA+YkrmFkHd38venoa8B6SdYYP14lfpC6LrUTg7tuBK4FZwNvAE+6+1MzGRz2EAK40s6VmVghcj66DXCdpHIJIdout+2hc1H20dikeh7B5c8mypk1VvSSSbpnqPirC2LG7JwEIz8eOzUw8IrInJQKJlcYhiGQ/JQKJlcYhiGQ/JQKJlcYhiGQ/JQKJVSrGIajXkUi84hxHIALUbBxC6V5HxbOfFu9XRGpOJQLJaup1JBI/JQLJaup1JBI/JQLJaup1JBI/JQLJaup1JBI/JQLJapr9VCR+6jUkWU+zn4rESyUCEZEcp0QgIpLjlAikztPIZJHyqY1A6jSNTBapmEoEUqdpZLJIxZQIpE7TyGSRiikRSJ2mkckiFVMikDpNI5NFKqZEIHWaRiaLVEy9hqTO08hkkfKpRCAikuNiTQRmNsDM3jGzFWY2pozXrzezZWa2xMxeMLN2ccYjIiJ7ii0RmFl9YBIwEDgKGGZmR5Va7Q2gwN27AE8Ct8cVj4iIlC3OEkEvYIW7r3T3b4GpwJDEFdz9JXcvHu7zGtAmxnhERKQMcSaC1sCHCc+LomXJ/AiYWdYLZjbKzBaY2YK1a9emMEQREcmKxmIzGwEUAHeU9bq7T3b3AncvaNWqVXqDk5ynSeukrouz++ga4LCE522iZbsxs1OAscCJ7v5NjPGIVJkmrZNcEGeJYD7Qwczam1kjYCgwPXEFM+sG/BEY7O6fxRiLSLVo0jrJBbElAnffDlwJzALeBp5w96VmNt7MBker3QE0A/5qZoVmNj3J7kQyQpPWSS6IdWSxu88AZpRadkvC41PifH+RmmrbNlQHlbVcpK7IisZikWylSeskFygRiJRDk9ZJLtCkcyIV0KR1UtepRCASM41DkGynEoFIjDQOQWoDlQhEYqRxCFIbKBGIxEjjEKQ2UCIQiVGy8QYahyDZRIlAJEYahyC1gRKBSIw0DkFqAyUCkZgNHw6rVsHOneG+OklAXVAlTuo+KpLl1AVV4qYSgUiWUxdUiZsSgUiWUxdUiZsSgUiWUxdUiZsSgUiWUxdUiZsSgUiWS0UXVPU6kvKo15BILVCTqbDV60gqohKBSB2nXkdSESUCkTpOvY6kIkoEInWceh1JRZQIROq4VPQ6UmNz3RZrIjCzAWb2jpmtMLMxZbzez8wWmdl2MzsnzlhEclVNex0VNzavXg3uJY3NSgZ1h7l7PDs2qw+8C3wfKALmA8PcfVnCOnlAC+BnwHR3f7Ki/RYUFPiCBQtiiVlE9pSXF07+pbVrFybRk9rBzBa6e0FZr8VZIugFrHD3le7+LTAVGJK4gruvcvclwM4Y4xCRGkhFY7OqlrJbnImgNfBhwvOiaFmVmdkoM1tgZgvWrl2bkuBEpHJq2tisqqXsVysai919srsXuHtBq1atMh2OSE6paWOzxjFkvzgTwRrgsITnbaJlIlKL1LSxWVVL2S/OKSbmAx3MrD0hAQwFzo/x/UQkJjWZ4qJt27Ibm6tataQpMuITW4nA3bcDVwKzgLeBJ9x9qZmNN7PBAGbW08yKgHOBP5rZ0rjiEZHMUNVS9ou1jcDdZ7h7R3c/wt0nRMtucffp0eP57t7G3fd29wPc/eg44xGR9FPVUvbT7KMiEjtVLWW3WtFrSERyVzZULdX1EoUSgYhktUxXLeXCOAglAhHJesOHh+ksdu4M91Wp0qnpgLhcKFEoEYhInVbTqqVsKFHEnUiUCESkTqtp1VKmSxTpqJqKbfbRuGj2URFJp9K9jiCUKCqbTOrVCyfw0sxCVVdFUjX7a6ZmHxURqfUyXaJIx6VGlQhERCpQk8bqmrZRpONSo0oEIiIxqmmJIhWXGq2IRhaLiMSsJiOri7cbOzZUB7VtG5JAKkdFKxGIiGS5miSSylDVkIhIjlMiEBHJcUoEIiI5TolARCTHKRGIiOS4WjfFhJmtBcoYcJ0VWgKfZzqIcii+msn2+CD7Y1R8NVOT+Nq5e6uyXqh1iSCbmdmCZHN5ZAPFVzPZHh9kf4yKr2biik9VQyIiOU6JQEQkxykRpNbkTAdQAcVXM9keH2R/jIqvZmKJT20EIiI5TiUCEZEcp0QgIpLjlAiqyMwOM7OXzGyZmS01s2vKWOckM9tgZoXR7ZY0x7jKzN6M3nuP63pacJeZrTCzJWbWPY2xHZlwXArNbKOZXVtqnbQfPzP7s5l9ZmZvJSzb38yeM7P3ovv9kmx7UbTOe2Z2UZpiu8PMlkd/v7+Z2b5Jti33uxBzjOPMbE3C33FQkm0HmNk70fdxTBrjezwhtlVmVphk21iPYbJzSlq/f+6uWxVuwCFA9+hxc+Bd4KhS65wE/CODMa4CWpbz+iBgJmDAscC/MxRnfeATwkCXjB4/oB/QHXgrYdntwJjo8Rjgt2Vstz+wMrrfL3q8Xxpi+wHQIHr827Jiq8x3IeYYxwE/q8R34H3gcKARsLj0/1Nc8ZV6/X+AWzJxDJOdU9L5/VOJoIrc/WN3XxQ93gS8DbTObFRVNgR4xIPXgH3N7JAMxPE94H13z/hIcXefA3xRavEQ4OHo8cPAGWVseirwnLt/4e5fAs8BA+KOzd2fdfft0dPXgDapfM+qSnL8KqMXsMLdV7r7t8BUwnFPqfLiMzMDfgg8lur3rYxyzilp+/4pEdSAmeUB3YB/l/HycWa22MxmmtnR6Y0MB541s4VmNqqM11sDHyY8LyIzyWwoyf/5Mnn8ih3k7h9Hjz8BDipjnWw4lpcQSnhlqei7ELcro+qrPyep2siG43cC8Km7v5fk9bQdw1LnlLR9/5QIqsnMmgH/B1zr7htLvbyIUN3RFfgDMC3N4R3v7t2BgcBPzKxfmt+/QmbWCBgM/LWMlzN9/PbgoRyedX2tzWwssB2YkmSVTH4X7gWOAPKBjwnVL9loGOWXBtJyDMs7p8T9/VMiqAYza0j4g01x96dKv+7uG939q+jxDKChmbVMV3zuvia6/wz4G6H4nWgNcFjC8zbRsnQaCCxy909Lv5Dp45fg0+Iqs+j+szLWydixNLORwOnA8OhEsYdKfBdi4+6fuvsOd98J3J/kvTP6XTSzBsBZwOPJ1knHMUxyTknb90+JoIqi+sQ/AW+7+++SrHNwtB5m1otwnNelKb69zax58WNCo+JbpVabDlxowbHAhoQiaLok/RWWyeNXynSguBfGRcDfy1hnFvADM9svqvr4QbQsVmY2ALgRGOzum5OsU5nvQpwxJrY7nZnkvecDHcysfVRKHEo47ulyCrDc3YvKejEdx7Ccc0r6vn9xtYTX1RtwPKGItgQojG6DgNHA6GidK4GlhB4QrwF90hjf4dH7Lo5iGBstT4zPgEmE3hpvAgVpPoZ7E07s+yQsy+jxIySlj4FthHrWHwEHAC8A7wHPA/tH6xYADyRsewmwIrpdnKbYVhDqhou/g/dF6x4KzCjvu5DG4/eX6Pu1hHBSO6R0jNHzQYSeMu/HFWNZ8UXLHyr+3iWsm9ZjWM45JW3fP00xISKS41Q1JCKS45QIRERynBKBiEiOUyIQEclxSgQiIjlOiUAkYmY7bPeZUVM2E6aZ5SXOfCmSTRpkOgCRLLLF3fMzHYRIuqlEIFKBaD7626M56V83s+9Ey/PM7MVoUrUXzKxttPwgC9cIWBzd+kS7qm9m90dzzj9rZk2i9a+O5qJfYmZTM/QxJYcpEYiUaFKqaui8hNc2uHtn4G5gYrTsD8DD7t6FMOnbXdHyu4CXPUya150wIhWgAzDJ3Y8G1gNnR8vHAN2i/YyO56OJJKeRxSIRM/vK3ZuVsXwVcLK7r4wmB/vE3Q8ws88J0yZsi5Z/7O4tzWwt0Mbdv0nYRx5h3vgO0fObgIbu/isz+yfwFWGW1WkeTbgnki4qEYhUjid5XBXfJDzeQUkb3WmEuZ+6A/OjGTFF0kaJQKRyzku4/1f0eB5htkyA4cDc6PELwBUAZlbfzPZJtlMzqwcc5u4vATcB+wB7lEpE4qRfHiIlmtjuFzD/p7sXdyHdz8yWEH7VD4uWXQU8aGY3AGuBi6Pl1wCTzexHhF/+VxBmvixLfeB/o2RhwF3uvj5Fn0ekUtRGIFKBqI2gwN0/z3QsInFQ1ZCISI5TiUBEJMepRCAikuOUCEREcpwSgYhIjlMiEBHJcUoEIiI57v8DTs0sj+M8y3oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc8d7aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과제시작부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a535cfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim                        4.1.2\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ~/aiffel/sentiment_classification/data\n",
    "! pip list | grep gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9ef5606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ac50afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c61c9f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00062114,  0.00054922, -0.03315588, -0.01317223,  0.05633358,\n",
       "       -0.04311547,  0.00903476, -0.02611109,  0.03278509, -0.03870131,\n",
       "       -0.02248124, -0.02676762, -0.03215281, -0.01361962,  0.03738719,\n",
       "       -0.01576204], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c1d1e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beauty', 0.9001352787017822),\n",
       " ('course', 0.8268925547599792),\n",
       " ('believable', 0.8211094737052917),\n",
       " ('manga', 0.8046944737434387),\n",
       " ('notch', 0.7996604442596436),\n",
       " ('great', 0.7950104475021362),\n",
       " ('finds', 0.7948476672172546),\n",
       " ('delightfully', 0.7802827954292297),\n",
       " ('rain', 0.779308021068573),\n",
       " ('enjoy', 0.7772877216339111)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "975f0446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link '/aiffel/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!ln -s ~/data/GoogleNews-vectors-negative300.bin.gz ~/aiffel/sentiment_classification/data\n",
    "# Google의 Word2Vec 모델을 가져와 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d896f3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3234c93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73d53595",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a7ffff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "571da65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 84ms/step - loss: 0.6919 - accuracy: 0.5236 - val_loss: 0.6892 - val_accuracy: 0.5606\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.6622 - accuracy: 0.6013 - val_loss: 0.6321 - val_accuracy: 0.6504\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.5401 - accuracy: 0.7508 - val_loss: 0.4611 - val_accuracy: 0.7913\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.3591 - accuracy: 0.8497 - val_loss: 0.3955 - val_accuracy: 0.8235\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.2531 - accuracy: 0.9029 - val_loss: 0.3511 - val_accuracy: 0.8465\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.1843 - accuracy: 0.9378 - val_loss: 0.3402 - val_accuracy: 0.8564\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.1362 - accuracy: 0.9614 - val_loss: 0.3587 - val_accuracy: 0.8502\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.1005 - accuracy: 0.9749 - val_loss: 0.3661 - val_accuracy: 0.8536\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0688 - accuracy: 0.9882 - val_loss: 0.3643 - val_accuracy: 0.8581\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0481 - accuracy: 0.9947 - val_loss: 0.3765 - val_accuracy: 0.8581\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0336 - accuracy: 0.9975 - val_loss: 0.3901 - val_accuracy: 0.8583\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0243 - accuracy: 0.9985 - val_loss: 0.4107 - val_accuracy: 0.8569\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0191 - accuracy: 0.9991 - val_loss: 0.4190 - val_accuracy: 0.8571\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0146 - accuracy: 0.9992 - val_loss: 0.4306 - val_accuracy: 0.8583\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0116 - accuracy: 0.9993 - val_loss: 0.4464 - val_accuracy: 0.8567\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.4738 - val_accuracy: 0.8545\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0080 - accuracy: 0.9995 - val_loss: 0.4713 - val_accuracy: 0.8580\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.4805 - val_accuracy: 0.8583\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.4917 - val_accuracy: 0.8573\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.5040 - val_accuracy: 0.8582\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd6ae1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5551 - accuracy: 0.8425\n",
      "[0.5550908446311951, 0.8424800038337708]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "283539cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-11 프로젝트\n",
    "!ln -s ~/data/*.txt ~/aiffel/sentiment_classification/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6760ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 준비와 확인\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7882430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 구성\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3eade8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c0b862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구성을 위한 데이터 분석 및 가공\n",
    "# 3-1 데이터셋 내 문장 길이 분포\n",
    "# 3-2 적절한 최대 문장 길이 지정\n",
    "# 3-3 keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모델 구성 및 validation set 구성\n",
    "# 모델은 3가지 이상 다양하게 구성하여 실험해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8b5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Loss, Accuracy 그래프 시각화\n",
    "# 7. 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce64eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 한국어 Word2Vec 임베딩 활용하여 성능 개선"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
