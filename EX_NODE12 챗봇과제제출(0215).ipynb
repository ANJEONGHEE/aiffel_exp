{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5aea0d0",
   "metadata": {},
   "source": [
    "# 프로젝트 진행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0d036",
   "metadata": {},
   "source": [
    "# 프로젝트 : 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07d9a9",
   "metadata": {},
   "source": [
    "## 1. STEP 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9434cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "# mkdir -p ~/aiffel/songys_chatbot : 다운로드 받기\n",
    "\n",
    "$ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "$ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d9bfcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지 불러오기\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7548dde",
   "metadata": {},
   "source": [
    " 챗봇 데이터를 로드하여 상위 5개 샘플 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859be739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data = pd.read_csv('ChatBotData.csv')\n",
    "project_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b3ca7",
   "metadata": {},
   "source": [
    "이번 전처리는 정규 표현식(Regular Expression) 을 사용하여 \n",
    "구두점(punctuation) 을 제거하여 단어를 토크나이징(tokenizing) 하는 일에 방해가 되지 않도록 정제하는 것을 목표로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359dc27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수:', len(project_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd076aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(project_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169d6f6",
   "metadata": {},
   "source": [
    "질문과 대답에 대해서 상위 5개만 출력하여 구두점들이 띄어쓰기를 통해 분리되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2000ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "  # 단어와 구두점 사이에 공백 추가.\n",
    "  # ex) 12시 땡! -> 12시 땡 !\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a353b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  # 입력 문장에 대한 전처리\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력 문장에 시작 토큰과 종료 토큰을 추가\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 예측 시작\n",
    "  for i in range(MAX_LENGTH):\n",
    "    predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "    # 현재 시점의 예측 단어를 받아온다.\n",
    "    predictions = predictions[:, -1:, :]\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 현재 시점의 예측 단어를 output(출력)에 연결한다.\n",
    "    # output은 for문의 다음 루프에서 디코더의 입력이 된다.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  # 단어 예측이 모두 끝났다면 output을 리턴.\n",
    "  return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c31b07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
    "  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4196038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c069ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f442e641",
   "metadata": {},
   "source": [
    "질문과 대답에 대해서 상위 5개만 출력하여 구두점들이 띄어쓰기를 통해 분리되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77773459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "640bb181",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1864024003.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 구두점에 대해서 띄어쓰기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# ex) 12시 땡! -> 12시 땡 !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([?.!,])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\" \\1 \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9348813",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/3979030667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 구두점에 대해서 띄어쓰기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# ex) 12시 땡! -> 12시 땡 !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"([?.!,])\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr\" \\1 \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    # 구두점에 대해서 띄어쓰기\n",
    "    # ex) 12시 땡! -> 12시 땡 !\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "279700b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/325208107.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'questions' is not defined"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c1e5b",
   "metadata": {},
   "source": [
    "단어 집합 생성 : 서브워드텍스트인코더를 사용하여 질문, 답변 데이터로부터 단어 집합(Vocabulary) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8610b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b55b93",
   "metadata": {},
   "source": [
    "단어 집합이 생성되었다. \n",
    "seq2seq에서 배웠던 것처럼 인코더-디코더 모델 계열에는 디코더의 입력으로 사용할 시작을 의미하는 시작 토큰 SOS와 종료 토큰 EOS 또한 존재한다. \n",
    "해당 토큰들도 단어 집합에 포함시킬 필요가 있으므로 이 두 토큰에 정수를 부여해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d7844a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 대한 정수 부여하기\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2로 명시하기\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c46c5a",
   "metadata": {},
   "source": [
    "시작 토큰과 종료 토큰 두개를 추가해주었으니 단어 집합의 크기도 +2를 해주기\n",
    "시작 토큰의 번호와 종료 토큰의 번호, 그리고 단어 집합의 크기를 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59895fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490640f",
   "metadata": {},
   "source": [
    "패딩에 사용될 0번 토큰부터 마지막 토큰인 8,179번 토큰까지의 개수를 카운트하면 단어 집합의 크기는 8,180개입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d96f1c",
   "metadata": {},
   "source": [
    "정수 인코딩과 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d9f46",
   "metadata": {},
   "source": [
    "단어 집합을 생성한 후에는 서브워드텍스트인코더의 토크나이저로 정수 인코딩을 진행할 수 있습니다. 이는 토크나이저의 .encode()를 사용하여 가능합니다. 우선 임의로 선택한 20번 질문 샘플. 즉, questions[20]을 가지고 정수 인코딩을 진행해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ed4e5",
   "metadata": {},
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n",
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42e962",
   "metadata": {},
   "source": [
    "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a802a9",
   "metadata": {},
   "source": [
    "임의의 질문 문장이 정수 시퀀스로 변환되었습니다. 반대로 정수 인코딩 된 결과는 다시 decode()를 사용하여 기존의 텍스트 시퀀스로 복원할 수 있습니다. 20번 질문 샘플을 가지고 정수 인코딩하고, 다시 이를 디코딩하는 과정은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4624441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장: 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
    "# 임의의 입력 문장을 sample_string에 저장\n",
    "sample_string = questions[20]\n",
    "\n",
    "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print ('기존 문장: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f952b",
   "metadata": {},
   "source": [
    "정수 인코딩 된 문장을 .decode()을 하면 자동으로 서브워드들까지 다시 붙여서 기존 단어로 복원해줍니다. 가령, 정수 인코딩 문장을 보면 정수가 7개인데 기존 문장의 띄어쓰기 단위인 어절은 4개밖에 존재하지 않습니다. 이는 '가스비'나 '비싼데'라는 한 어절이 정수 인코딩 후에는 두 개 이상의 정수일 수 있다는 겁니다. 각 정수가 어떤 서브워드로 맵핑되는지 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6de792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ----> 가스\n",
      "611 ----> 비 \n",
      "3509 ----> 비싼\n",
      "141 ----> 데 \n",
      "685 ----> 감기 \n",
      "3747 ----> 걸리\n",
      "849 ----> 겠어\n"
     ]
    }
   ],
   "source": [
    "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
    "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1789bea",
   "metadata": {},
   "source": [
    "샘플 1개를 가지고 정수 인코딩과 디코딩을 수행해보았습니다. 이번에는 전체 데이터에 대해서 정수 인코딩과 패딩을 진행합니다. 이를 위한 함수로 tokenize_and_filter()를 만듭니다. 여기서는 임의로 패딩의 길이는 40으로 정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32ae9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    tokenized_inputs.append(sentence1)\n",
    "    tokenized_outputs.append(sentence2)\n",
    "\n",
    "  # 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "874db9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01436921",
   "metadata": {},
   "source": [
    "정수 인코딩과 패딩이 진행된 후의 데이터의 크기를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "deb30e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (11823, 40)\n",
      "답변 데이터의 크기(shape) : (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c75e2",
   "metadata": {},
   "source": [
    "질문과 답변 데이터의 모든 문장이 모두 길이 40으로 변환되었습니다. 임의로 0번 샘플을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0ad896a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 0번 샘플을 임의로 출력\n",
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450e785",
   "metadata": {},
   "source": [
    "길이 40을 맞추기 위해 뒤에 0이 패딩된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0eb91c",
   "metadata": {},
   "source": [
    "4. 인코더와 디코더의 입력, 그리고 레이블 만들기."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52253fe",
   "metadata": {},
   "source": [
    "tf.data.Dataset을 사용하여 데이터를 배치 단위로 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be7f503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n",
    "# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9f8b611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1de896c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b5e45",
   "metadata": {},
   "source": [
    "5. 트랜스포머 만들기\n",
    "이제 트랜스포머를 만들어봅시다. 하이퍼파라미터를 조정하여 실제 논문의 트랜스포머보다는 작은 모델을 만듭니다.\n",
    "여기서 선택한 주요 하이퍼파라미터의 값은 다음과 같습니다.\n",
    "\n",
    "dmodel = 256\n",
    "num_layers = 2\n",
    "num_heads = 8\n",
    "dff = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "363fca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8071eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률과 옵티마이저를 정의하고 모델을 컴파일합니다.\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7bbc996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 15s 52ms/step - loss: 1.4480 - accuracy: 0.0214\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 1.1777 - accuracy: 0.0487\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 1.0040 - accuracy: 0.0508\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 10s 52ms/step - loss: 0.9275 - accuracy: 0.0547\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.8693 - accuracy: 0.0577\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.8091 - accuracy: 0.0618\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.7434 - accuracy: 0.0678\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.6706 - accuracy: 0.0757\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.5931 - accuracy: 0.0839\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.5119 - accuracy: 0.0935\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.4303 - accuracy: 0.1033\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.3502 - accuracy: 0.1145\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.2758 - accuracy: 0.1253\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.2096 - accuracy: 0.1356\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.1555 - accuracy: 0.1446\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.1121 - accuracy: 0.1524\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0816 - accuracy: 0.1579\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0624 - accuracy: 0.1616\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0519 - accuracy: 0.1635\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0459 - accuracy: 0.1644\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0431 - accuracy: 0.1647\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0406 - accuracy: 0.1651\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0363 - accuracy: 0.1660\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0324 - accuracy: 0.1670\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0278 - accuracy: 0.1681\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0247 - accuracy: 0.1690\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0222 - accuracy: 0.1695\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0199 - accuracy: 0.1701\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0180 - accuracy: 0.1707\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0172 - accuracy: 0.1709\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0159 - accuracy: 0.1711\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0142 - accuracy: 0.1716\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0136 - accuracy: 0.1717\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0127 - accuracy: 0.1720\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0109 - accuracy: 0.1724\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0107 - accuracy: 0.1726\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0099 - accuracy: 0.1727\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0095 - accuracy: 0.1728\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0092 - accuracy: 0.1728\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0088 - accuracy: 0.1729\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0083 - accuracy: 0.1731\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0077 - accuracy: 0.1733\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0077 - accuracy: 0.1733\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0070 - accuracy: 0.1734\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0068 - accuracy: 0.1734\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0065 - accuracy: 0.1735\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0062 - accuracy: 0.1736\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0062 - accuracy: 0.1736\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 0.0059 - accuracy: 0.1737\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.0055 - accuracy: 0.1737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02a026f2b0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50회 반복\n",
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e428f6",
   "metadata": {},
   "source": [
    "6. 챗봇 평가하기.\n",
    "챗봇을 평가하기 위한 세 개의 함수를 구현합니다. predict 함수에서 evaluate 함수를 호출하고 evaluate 함수에서 preprocess_sentence 함수를 호출하는 구조입니다. 사용자의 입력이 파이썬의 문자열로 입력되면 preprocess_sentence 함수에서 문자열에 대한 전처리를 수행합니다. 해당 전처리는 학습 전 질문 데이터와 답변 데이터에서 했던 전처리와 동일한 전처리입니다. 전처리가 진행된 문자열에 대해서 evaluate 함수는 트랜스포머 모델에 전처리가 진행된 사용자의 입력을 전달하고, 디코더를 통해 계속해서 현재 시점의 예측. 다시 말해 챗봇의 대답에 해당하는 단어를 순차적으로 예측합니다. 여기서 예측된 단어들은 문자열이 아니라 정수인 상태이므로 evaluate 함수가 리턴하는 것은 결과적으로 정수 시퀀스입니다. predict 함수는 evaluate 함수로부터 전달받은 챗봇의 대답에 해당하는 정수 시퀀스를 문자열로 다시 디코딩을 하고 사용자에게 챗봇의 대답을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b341a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "  prediction = evaluate(sentence)\n",
    "\n",
    "  # prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\n",
    "  # tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2525b488",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'START_TOKEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/507289801.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습된 트랜스포머에 임의로 생각나는 말들을 적어보았습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"영화 볼래?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_13/2843746402.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# prediction == 디코더가 리턴한 챗봇의 대답에 해당하는 정수 시퀀스\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# tokenizer.decode()를 통해 정수 시퀀스를 문자열로 디코딩.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13/3722374773.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# 입력 문장에 시작 토큰과 종료 토큰을 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   sentence = tf.expand_dims(\n\u001b[0;32m----> 7\u001b[0;31m       START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'START_TOKEN' is not defined"
     ]
    }
   ],
   "source": [
    "# 학습된 트랜스포머에 임의로 생각나는 말들을 적어보았습니다.\n",
    "output = predict(\"영화 볼래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d5cd07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 고민이 있어\n",
      "Output: 저는 고민이 없어요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1cbea17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너무 화가나\n",
      "Output: 그럴수록 당신이 힘들 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66e06ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 카페갈래?\n",
      "Output: 저는 좋아요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dbf12c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하고싶당\n",
      "Output: 아무 생각 하지 말고 푹 주무세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c6ecaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하자\n",
      "Output: 게임하세요 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5ea263d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 넌 누구냐?\n",
      "Output: 저는 위로봇입니다 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"넌 누구냐?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dad92454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  바다가 보고 싶어\n",
      "Output: 탁 트인 바다 좋죠 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\" 바다가 보고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbbb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25293faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f013db7",
   "metadata": {},
   "source": [
    "## 1. 단어장(Vocabulary) 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1f7a3",
   "metadata": {},
   "source": [
    "이때 디코더의 문장 생성 과정에서 사용할 '시작 토큰'과 '종료 토큰'에 대해서도 임의로 단어장에 추가하여서 정수를 부여해 줍니다.\n",
    "이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰 수를 번호로 부여하면 되겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db70b123",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1953736273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"슝=3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be3dadcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/2667472866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 시작 토큰과 종료 토큰에 부여된 정수를 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'START_TOKEN의 번호 :'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'END_TOKEN의 번호 :'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 각각 8,331과 8,332라는 점에서 현재 단어장의 크기가 8,331(0번부터 8,330번)이라는 의미\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 부여된 정수를 출력\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "# 각각 8,331과 8,332라는 점에서 현재 단어장의 크기가 8,331(0번부터 8,330번)이라는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80772a49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1204836560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 두 개의 토큰을 추가해 주었기 때문에 단어장의 크기도 +2임을 명시\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)\n",
    "# 두 개의 토큰을 추가해 주었기 때문에 단어장의 크기도 +2임을 명시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a673f",
   "metadata": {},
   "source": [
    "## 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d0165",
   "metadata": {},
   "source": [
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, \n",
    "tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca7abf63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [60, 8, 37, 8172, 49]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [7824, 1223, 19, 61, 2, 4, 336, 10, 1595, 14, 1104, 698, 3263, 263, 16, 71, 14, 107, 2133, 900, 3, 59, 4, 23, 355, 204, 60, 8, 37, 885, 2289, 8107, 344, 1001, 5179, 4214, 342, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.  22번째 샘플을 tokenizer.encode()의 입력으로 사용해서 변환 결과 보기\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94715f",
   "metadata": {},
   "source": [
    "각 단어에 고유한 정수가 부여된 Vocabulary를 기준으로 단어 시퀀스가 정수 시퀀스로 인코딩된 결과를 확인할 수 있습니다. \n",
    "위의 결과와 마찬가지로 질문과 답변 셋에 대해서 전부 정수 인코딩을 수행합니다. \n",
    "이와 동시에 문장의 최대 길이를 정하고, 해당 길이로 패딩(padding) 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f3c977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a19205f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c29692",
   "metadata": {},
   "source": [
    "정수 인코딩 과정을 수행하면서 샘플의 길이가 40을 넘는 경우는 샘플들을 필터링하였으므로 일부 샘플이 제외되었습니다. 단어장의 크기와 샘플의 개수를 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9de25450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8333\n",
      "필터링 후의 질문 샘플 개수: 44095\n",
      "필터링 후의 답변 샘플 개수: 44095\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c4902",
   "metadata": {},
   "source": [
    "## 3. 교사 강요(Teacher Forcing) 사용하기\n",
    "tf.data.Dataset API는 훈련 프로세스의 속도가 빨라지도록 입력 파이프라인을 구축하는 API입니다.\n",
    "\n",
    "이를 적극 사용하기 위해서 질문과 답변의 쌍을 tf.data.Dataset의 입력으로 넣어주는 작업을 합니다.\n",
    "\n",
    "이때, 디코더의 입력과 실제값(레이블)을 정의해 주기 위해서는 교사 강요(Teacher Forcing) 이라는 언어 모델의 훈련 기법을 이해해야만 합니다. \n",
    "아래의 글을 통해 교사 강요에 대해 알아봅시다. (모두 읽을 필요는 없고, 교사 강요 부분까지만 읽어도 됩니다.)\n",
    "\n",
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. \n",
    "이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60fca2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34c50b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 12-12 앞서 사용한 인코더 층 함수와 디코더 층 함수를 사용하여 트랜스포머 함수를 정의\n",
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd69a69",
   "metadata": {},
   "source": [
    "## STEP4. 모델 생성\n",
    "### 4-1 모델생성\n",
    "num_layers, d-Model, units는 전부 사용자가 정할 수 있는 하이퍼파라미터 값입니다.\n",
    "\n",
    "논문에서 num_layers는 6, d-Model은 512였지만, 빠르고 원활한 훈련을 위해 여기서는 각 하이퍼파라미터를 논문에서보다는 작은 값을 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8638dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3187456     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3714816     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8333)   2141581     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,043,853\n",
      "Trainable params: 9,043,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346280c",
   "metadata": {},
   "source": [
    "## 4-2 손실 함수(Loss function)\n",
    "레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da1d00f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 손실함수\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0df353a4",
   "metadata": {},
   "source": [
    "### 커스텀 된 학습률(Learning rate)\n",
    "딥러닝 모델학습 시 learning rate는 매우 중요한 하이퍼파라미터입니다. 최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다. 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다.\n",
    "\n",
    "논문에 나온 공식을 참고하여 커스텀 학습률 스케줄러를 통한 아담 옵티마이저를 사용합니다. 논문에 나온 공식은 다음과 같습니다.\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "715eaf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f581e",
   "metadata": {},
   "source": [
    "그러면 방금 정의한 커스텀 학습률 스케줄링 계획을 시각화해 봅시다. \n",
    "위에 언급한 수식은 step_num−0.5 에 비례하는 부분과 step_num에 비례하는 부분 중 작은 쪽을 택하도록 되어 있습니다. \n",
    "그래서 학습 초기에는 learning_rate가 step\\_numstep_num에 비례해서 증가하다가 이후로는 감소하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bde7a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c8dbe7",
   "metadata": {},
   "source": [
    "### 모델 컴파일\n",
    "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f7090d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83c45c",
   "metadata": {},
   "source": [
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d5d49",
   "metadata": {},
   "source": [
    "### 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d7c461c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "689/689 [==============================] - 83s 108ms/step - loss: 2.1131 - accuracy: 0.0429\n",
      "Epoch 2/20\n",
      "689/689 [==============================] - 75s 108ms/step - loss: 1.5031 - accuracy: 0.0784\n",
      "Epoch 3/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 1.3962 - accuracy: 0.0857\n",
      "Epoch 4/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 1.3351 - accuracy: 0.0904\n",
      "Epoch 5/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 1.2830 - accuracy: 0.0945\n",
      "Epoch 6/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 1.2362 - accuracy: 0.0979\n",
      "Epoch 7/20\n",
      "689/689 [==============================] - 66s 95ms/step - loss: 1.1810 - accuracy: 0.1023\n",
      "Epoch 8/20\n",
      "689/689 [==============================] - 75s 108ms/step - loss: 1.1197 - accuracy: 0.1075\n",
      "Epoch 9/20\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 1.0628 - accuracy: 0.1133\n",
      "Epoch 10/20\n",
      "689/689 [==============================] - 73s 105ms/step - loss: 1.0099 - accuracy: 0.1188\n",
      "Epoch 11/20\n",
      "689/689 [==============================] - 68s 99ms/step - loss: 0.9612 - accuracy: 0.1248\n",
      "Epoch 12/20\n",
      "689/689 [==============================] - 75s 108ms/step - loss: 0.9165 - accuracy: 0.1305\n",
      "Epoch 13/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 0.8760 - accuracy: 0.1360\n",
      "Epoch 14/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 0.8399 - accuracy: 0.1414\n",
      "Epoch 15/20\n",
      "689/689 [==============================] - 66s 95ms/step - loss: 0.8064 - accuracy: 0.1466\n",
      "Epoch 16/20\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.7748 - accuracy: 0.1514\n",
      "Epoch 17/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 0.7465 - accuracy: 0.1560\n",
      "Epoch 18/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 0.7211 - accuracy: 0.1603\n",
      "Epoch 19/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 0.6972 - accuracy: 0.1642\n",
      "Epoch 20/20\n",
      "689/689 [==============================] - 74s 108ms/step - loss: 0.6744 - accuracy: 0.1683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02b6f82c10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련하기\n",
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49026b40",
   "metadata": {},
   "source": [
    "##  챗봇 테스트하기\n",
    "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.\n",
    "\n",
    "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
    "\n",
    "위의 과정을 모두 담은 decoder_inference() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1adb2bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 12-13\n",
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1206b1",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa3e17ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bed6a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Where have you been?\n",
      "출력 : i m looking for tod . i m going to have a very long time .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m looking for tod . i m going to have a very long time .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('Where have you been?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbe4534a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : It's a trap\n",
      "출력 : what s the matter ? there s only one who s always looking for a flask .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'what s the matter ? there s only one who s always looking for a flask .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53347307",
   "metadata": {},
   "source": [
    "# 프로젝트 진행하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
